---
title: <center> STAT3120 Applied Bayesian Methods </center>
subtitle: <center> Semester 2, 2016 </center>
author: 
  Benjamin G. Moran;
  <right> c3076448@uon.edu.au </right>
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    includes: 
      before_body: eqnnumber.js
    mathjax: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
require(ggplot2)
require(broom)
```

Due Monday 22 August 2016 (on-campus by 3pm, distance by 5pm)

Late assignments will not be accepted without prior written permission of the lecturer.

***

###Total marks: 50

Marking Criteria:

1.	Answers must be written in clear English with all appropriate working and/or supporting computer output shown.
2.	Raw computer output without explanatory text is unacceptable.
3.	Students are required to understand the content in Weeks 1-4 to answer these questions.
4.	As part of your workings you should include applicable R-code.

***
 
**Question 1 [Total: 15 marks]**

**Law case (taken from Rossman and Short, 1995, Journal of Statistics Education).**

Joseph Jameison was charged with multiple rapes in 1987 in Allegheny County in the US. DNA evidence from the scenes of the crimes revealed that the attacker displayed the genetic marker PGM2+1- in his DNA. This marker has only a 0.32% prevalence in the general population.

(a) Discuss how you might choose a prior probability that Jameison is guilty. Explain and defend your choice (do not set a specific number yet). [2 marks]

(b) Update your prior with the observed information. Display the full formula for Bayes’ rule in terms of the as yet unknown prior Pr(guilty). [3 marks]

```{r Q1b}
pr.guilty <- seq(0,0.99,by=0.0001)
pr.marker <- 0.0032
pr.notguilty <- 1-pr.guilty
pr.post <- (1*pr.guilty)/(1*(pr.guilty) + pr.marker*(pr.notguilty))
prob.dens <- as.data.frame(rbind(cbind(pr.guilty, pr.post),c(1,1)))

ggplot2::ggplot(prob.dens, aes(x=pr.guilty,y=pr.post)) +
  geom_line(data=prob.dens) +
  geom_hline(yintercept=0.975)

mpr.guilt <- which(pr.post > 0.975)
pr.guilty[mpr.guilt[1]]
```

(c) Display the posterior probability of guilt using a range of suitable values for the prior Pr(guilty). [3 marks]

(d) Say that a jury wants to be at least 97.5% sure of guilt before returning a guilty verdict. What is the smallest prior probability of guilt that could be chosen to ensure this level of probability. [2 marks]

(e)	Suppose there are 4,622 males living in Allegheny County. Given that we have found 1 male with PGM2+1- in his DNA, what is the probability that other males in the county also display this marker?	[3 marks]

(f) Should Jameison be found guilty on the DNA evidence alone? Discuss.	[2 marks]

*Q1: is just like a Pr(disease | positive test result) type of problem*

**Question 2	[Total : 10 marks]**

*Part 1:* ABC book distributors have a new book that they hope will be popular with their customers. To obtain an idea of how popular it will be they choose a random sample of 40 customers, ring them, give them a brief description and ask whether they would like to buy the book. 15 of the sample decided to buy the book. What inference can we make about the true proportion of the population of customers that will buy the new book based on this sample?
```{r 2.Part1, include = TRUE}
n <- 40; y <- 15
dbinom(15,40, prob = 0.5)
```
(a) Under a uniform prior, derive the posterior distribution for the unknown true proportion. [2 marks]

$$\begin{aligned} p(\theta | y = `r y`) &\propto Pr(y = `r y` | \theta)p(\theta) \\
&\propto \theta^ {`r y`}(1-\theta)^ {`r n-y`}
\end{aligned}$$

```{r Q2 - 1a}
x <- seq(0,1,by = 0.01); a = 15; b = 40

dens <- dbeta(
  x,
  a + 1,
  b - a + 1
  )

posterior.dens.unif <- as.data.frame(cbind(x,dens))

ggplot(
  data = posterior.dens.unif,
  aes(x,dens)
  ) +
  geom_line()
```

(b) Is ABC likely to achieve 50% of their population of customers buying the new book? [2 marks]

```{r Q2 - 1b}
x <- seq(0,1,by = 0.01); a = 15; b = 40

unif.data <- rbeta(
  10000,
  a + 1,
  b - a + 1
  )
```
Now, if we take the mean of generated data that is greater than $0.5\%$, we get 
```{r } 
mean(unif.data>0.5)
```
implying that it is not very likely that ABC will achieve their target. We can confirm this be calulating the mean of the whole sample.
```{r}
mean(unif.data)
```
which implies that the most likely outcome for ABC - using the given prior and likelihood - is that $\approx 38\%$ of their customers will purchase the book.

*Part 2:* In past ABC new book promotions they have found that on average 23.5% of their customers buy the book being promoted. In fact, the proportion of customers buying new books after phone promotions has a histogram that closely matches a $Beta(4,13)$ density.

(c) Can we use this as a prior density? Discuss.	[2 marks]

**Answer:** We can check this by generating some random samples from a $Beta(4,13)$ distribution and calculating the mean of those samples.

```{r Q2- 2c}
a = 3; b = 15

beta.data <- rbeta(
  10000,
  a + 1,
  b - a + 1
  )

mean(beta.data)
```
Which is $\approx 23.5\%$. Therefore, we can justifiably use $Beta(4,13)$ as a prior distribution.

(d) Assume the answer in (c) is yes and derive the corresponding posterior.	[2 marks]

```{r Q2- 2d}
x <- seq(0,1,by = 0.01); a1 <- 15; b1 <- 40; a2 <-  3; b2 <-  15

dens <- dbeta(
  x,
  (a1 + a2) + 1,
  (b1 + b2) - (a1 + a2) + 1
  )

posterior.dens.beta <- as.data.frame(cbind(x, dens))

ggplot(
  data = posterior.dens.beta,
  aes(x,dens)
  ) + 
  geom_line()

beta.data <- rbeta(
  10000,
  (a1 + a2) + 1,
  (b1 + b2) - (a1 + a2) + 1
  )

mean(beta.data>0.5)
mean(beta.data)


```

(e) How did this prior information affect the likelihood of at least 50% of ABC’s population of customers buying the new book?	[2 marks]

```{r Q2e}

ggplot() + 
  geom_line(
    data = posterior.dens.unif,
    aes(x,dens),
    color = "blue"
    ) + 
  geom_line(
    data = posterior.dens.beta,
    aes(x,dens),
    color = "red"
    )

mean(beta.data>0.5)
mean(beta.data)
```

***
 
**Question 3	[Total: 4 marks]**

Suppose you have a Beta(6,6) prior on the probability $\theta$ that a coin will yield a head when spun in a specified manner. The coin is independently spun 5 times. All you are told is that all 5 results were the same, i.e. either 5 heads or 5 tails. Derive your posterior density (up to a proportionality constant) for $\theta$ and sketch it.

**Answer:** We are given that the prior probability of $\theta$ is proportional to a $Beta(6,6)$ distribution:
$$f(\theta) \propto \theta^5(1-\theta)^5$$

```{r Q3a}
theta.prior <- seq(0,1,0.01)
prior.density  <- theta.prior^5*(1-theta.prior)^5 
prior.data <- as.data.frame(cbind(theta.prior, prior.density))

ggplot(
  prior.data,
  aes(theta.prior, prior.density)) + 
  geom_line()
```

We are also given that the data could represent only two possible outcomes - either all heads or all tails. Therefore, the likelihood of the data is equal to:
$$\begin{aligned} Pr(x|\theta) &= \binom{5}{0}(1-\theta)^5 + \binom{5}{5}\theta^5 \\ 
&= (1-\theta)^5 + \theta^5
\end{aligned}$$

```{r Q3b}
theta.like <- seq(0,1,0.01)
like.density  <- (1-theta.like)^5  + theta.like^5
like.data <- as.data.frame(cbind(theta.like, like.density))

ggplot(
  like.data,
  aes(theta.like, like.density)) + 
  geom_line()
```

So, we can derive the posterior by multiplying the prior by the likelihood:
$$\begin{aligned} f(\theta|x) &\propto Pr(x|\theta)f(\theta) \\
&\propto \theta^5(1-\theta)^5*\left((1-\theta)^5 + \theta^5\right) \\
&\propto \theta^5(1-\theta)^{10} + \theta^{10}(1-\theta)^5
\end{aligned}$$
Now let's sketch the distribution
```{r Q3}
theta.coin <- seq(0,1,0.01)
posterior.density  <- theta.coin^5*(1-theta.coin)^10 + theta.coin^10*(1-theta.coin)^5
coin.data <- as.data.frame(cbind(theta.coin, posterior.density))

ggplot() + 
  geom_line(
    data = coin.data,
    aes(theta.coin, posterior.density))
```

***

**Question 4	[Total: 9 marks]**

A treatment vs control group example discussed at various times in the literature is based on 11 successes in 11 treatments (i.e. 11/11), and a single failure in the control group (i.e. 0/1).

(a) Find a classical solution to the question of whether the treatment is successful. Bare output from a statistical package is acceptable, but without understanding the
procedure, it may be difficult to obtain full marks at (c).	[3 marks]

(b) Apply a Bayesian approach to this question, trying both the Bayes-Laplace and Jeffreys priors.	[4 marks]

(c) Briefly explain possible reasons behind the various differences.	[2 marks]


*Q4: re "classical solution", remember that the data from two sample proportions can be put in a 2x2 table, for which various tests are available (mostly not suitable for this extreme data!)*
```{r Q4 classical}

treatment.table <- matrix(c(11,0,0,1),ncol=2,byrow=TRUE)
colnames(treatment.table) <- c("Success","Failure")
rownames(treatment.table) <- c("Treatment","Control")
treatment.table <- as.table(treatment.table)
treatment.table
treatment.chisq <- broom::tidy(chisq.test(treatment.table))
treatment.chisq
```

```{r Q4 Bayes}
pt <-  1 # Probability of uccessful treatmetn outcome in Treatment group
pc <- 0 # Probability of successful treatmetn outcome in Control group

nt <- 11 # Size of Treatment Group
rt <- 11 # Number of successes for Treatment Group
nc <- 1 # Size of Control Group
rc <- 0 # Number of Success for Control Group.


like <- (pt^rt*(1-pt)^(nt-rt))*(pc^rc*(1-pc)^(nc-rc))




```
***

**Question 5	[Total: 4 marks]**

A random sample of n students is drawn from a large population, and their weights are measured. The average weight of the n sampled students is y = 150 pounds. Assume the weights in the population are Normally distributed with unknown mean $\theta$ and known standard deviation of 20 pounds. Suppose your prior distribution for $\theta$ is Normal with mean 180 and known standard deviation of 40 pounds.


Give your posterior distribution for $\theta$ . (Note that your answer will be a function of n.)

***
 
**Question 6	[Total: 8 marks]**

Consider the Uniform(0, $\theta$) distribution, i.e. $$p(x | \theta) = 1/\theta,	0 < x < \theta $$ from which a random sample $\{x_1,...,x_n\}$ is obtained. Note that $y_n = \text{max}\{x_1,...,x_n\}$ is a sufficient statistic.

(a) Derive the posterior distribution $p(\theta | x_1,...,x_n) = p(\theta | y_n)$, based on the noninformative prior $p(\theta) ∝ 1/ \theta.$ Be careful to use the correct likelihood and range!	[3 marks]

**Answer:** Firstly, we have that that the density of the uniform distribtion $\mathcal{U}[0,\theta]$ is:
```{r Q6a uniform}

```
From this we can calculate the Likelihood function be taking the product of $n\times$ the uniform density of a single r.v.

$$L(\theta|x) = \begin{cases} \prod\limits_{i=1}^{n} \frac{1}{\theta^{i}} & \text{max}\>\left\{x_1, x_2, \cdots, x_n\right\} \leq \theta \\
0 & otherwise 
\end{cases}
$$
(b) Plot this posterior for $y_n = 5$ and $n = 20$.	[2 marks]
**Answer:** With $y_n = \text{max}\>\left\{x_1, x_2, \cdots, x_n\right\} = 5$ and $n = 20$ we have a posterior distribution of $$Pr(\theta|x) = \begin{cases} \frac{1}{\theta^{21}} & \text{max}\>\left\{x_1, x_2, \cdots, x_{20}\right\} \leq \theta \\
0 & otherwise 
\end{cases}
$$

```{r Q6b}
y <- 5; n <- 20; a <- 5

theta <- seq(y,10, by = 0.001)
post.dens <- 1/(theta^(n+1))
dens <- as.data.frame(cbind(theta,post.dens))

theta.0 <- as.data.frame(seq(0,10, by = 0.001))

  ggplot2::ggplot() + 
    geom_line(
      data = dens,
      aes(theta,post.dens)
      ) + 
    geom_vline(
      xintercept=y,
      color= "red",
      linetype = 2
      ) +
    geom_segment(
      data = theta.0,
      x=0,xend=y,y=0,yend=0
      ) + 
    xlim(0,10)

```

From this it should be obvious that the MLE of $\theta$ is achieved whene $\theta = y_n$.

(c) For the data at (b), derive 95% credible intervals, both central and HPD. Which would you prefer and why? [3 marks]

*Q6: tests application of the Bayesian approach to a "general" problem (covered in many introductory stats books but not in the lecture notes), AND shows how it works very well here:-)*

***

####End of Assignment 1
