---
title: "Assignment3"
author: "Benjamin Moran"
date: "28 October 2016"
output: pdf_document
---

```{r setup, include=FALSE}
require(tufte)
require(knitr)
require(R2OpenBUGS)
require(lme4)
require(LearnBayes)
require(ggplot2)
opts_chunk$set(cache = TRUE)
opts_chunk$set(fig.align = 'center', fig.height = 7.5, fig.width = 15, collapse = TRUE, highlight = TRUE)
```
##Question 1

The bioassay data below was presented and analysed at various times during the course.

```{r q1table, echo=FALSE}
q1table <- matrix(
  c(-0.863,5,0,-0.296,5,1, -0.053,5,3,0.727,5,5),
    ncol = 3,
    nrow = 4, byrow = TRUE
  )
colnames(q1table) <- c("Log dosage",	"No. of animals","No. of deaths")
kable(q1table, format="markdown", align = rep("c", dim(q1table)[2] + 1), row.names = FALSE)
```		
This was an experiment done on 20 animals to estimate the toxicity of a certain drug. The data is the number of deaths (out of n) corresponding to a different dosage levels of the drug. We modeled this data as a binomial regression model as follows:

$$y_{t} \mid p_{t}  \sim Bin(5, p_{t} ) ; \\
logit(p_{t}) = log\left(\frac{p_{t}}{1 - p_{t}}\right)	= \alpha + \beta x_{t}
$$ 

#####(a) Perform inference for this model under a flat prior and find point estimates and 95% intervals for each parameter using WinBUGS.

```{r q1BUGS}
require(R2OpenBUGS)
require(coda)
#schools data in the R2OpenBUGS library

#define the model
bioassaymodel <- function(){
  for (i in 1:n) {
    logit(theta[i]) <- beta0 + beta1*xi[i] 
    yi[i] ~ dbin(theta[i],ni[i]) 
  } 
  beta0 ~  dnorm(0,0.001)
  beta1 ~  dnorm(0,0.001)
  LD50 <- (logit(0.50)-beta0)/beta1 
}
# write the model code out to a file
write.model(bioassaymodel, "bioassaymodel.txt")
model.file1 = paste(getwd(),"bioassaymodel.txt", sep="/")
## and let's take a look:
file.show("bioassaymodel.txt")

#prepare the data for input into OpenBUGS
xi <- c(-0.863,-0.296,-0.053,0.727) 
ni <- c(5,5,5,5)
yi <- c(0,1,3,5)
n <- 4
data <- list ("xi", "yi", "ni","n")

#initialization of variables
inits <- function(){
  list(beta0=0,beta1=1)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("beta0", "beta1","LD50")

#run the model
bioassay.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.chains = 4, 
                    n.iter = 2500, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,
                    codaPkg = FALSE)

#R will pause. When model is complete a prompt will reappear
attach(bioassay.sim,warn.conflicts = FALSE)
```
```{r Q1aSummary}
bioassay.sim$summary
```

#####(b) Compare the results obtained by WinBUGS and the MC sampling scheme (Lab 8 solutions). Comments on the results.
```{r Q1bMCSample, include = FALSE}
y=c(0,1,3,5) 
x=c(-0.863,-0.296,-0.053,0.727) 
px=seq(1,1000^2) 
dim(px)=c(1000,1000) 
a=seq(-5,10,by=15/999) 
b=seq(-3,50,by=53/999) 
sy=sum(y)

sxy=sum(x*y)
for(k in 1:1000) {
  for(j in 1:1000) {
    px[k,j]=a[k]*sy+b[j]*sxy-5*sum(log(1+exp(a[k]+b[j]*x)))
  }
}
px <- exp(px)

pxa=0
for(k in 1:1000) {
  pxa[k]=sum(px[k,])
}
pxa=pxa/sum(pxa)
cdfa <- cumsum(pxa) 

#MC Alpha
u=runif(5000,0,1) 
a1=0 
for(j in 1:5000){     
st=0;k=1 
     while(st==0){ 
         if(cdfa[k+1]>u[j]&cdfa[k]<u[j]){ 
           a1[j]=a[k];st=1}else{k=k+1} 
     }} 

# MC Beta
u <- runif(5000,0,1)
a1 <- 0
b1 <- 0
u <- runif(5000,0,1) 
for(j in 1:5000){ 
  st=0
  k=1
  while(st==0) {
    if(cdfa[k+1]>u[j]&cdfa[k]<u[j]) {
      a1[j]=a[k];st=1 
    } else {
        k=k+1
    }
  }
  pxb=px[k,]
  pxb=pxb/sum(pxb)
  cdfb=cumsum(pxb)
  st1=0
  k1=1
  u1=runif(1,0,1)
  while(st1==0) {
    if(cdfb[k1+1]>u1&cdfb[k1]<u1) {
      b1[j]=b[k1]
      st1=1
    } else {
        k1=k1+1
    }
  }
}
```
```{r MCplot, include = FALSE}
require(ggplot2)
attach(bioassay.sim,warn.conflicts = FALSE)
mean(a1)
quantile(a1,c(0.025,0.975))
mean(b1)
quantile(b1,c(0.025,0.975))
par(mfrow = c(2,3))

ld50=-a1/b1 
mean(ld50)
quantile(ld50,c(0.025,0.975)) 

numb0 <- as.data.frame(cbind(V1 = a1,scheme="MC",variable="beta0"))
numb1 <- as.data.frame(cbind(V1 = b1,scheme="MC",variable="beta1"))
numld50 <- as.data.frame(cbind(V1 = ld50,scheme="MC",variable="ld50"))

bugsb0 <- as.data.frame(cbind(sims.list$beta0,scheme="BUGS",variable="beta0"))
bugsb1 <- as.data.frame(cbind(sims.list$beta1,scheme="BUGS",variable="beta1"))
bugsld50 <- as.data.frame(cbind(sims.list$LD50,scheme="BUGS",variable="ld50"))

biohistbeta <- as.data.frame(rbind(numb0,numb1,bugsb0,bugsb1))
biohistbeta$V1 <- as.numeric(as.character(biohistbeta$V1))
biohistld50 <- as.data.frame(rbind(numld50,bugsld50))
biohistld50$V1 <- as.numeric(as.character(biohistld50$V1))
```
```{r Q1hists, echo=FALSE, warning = FALSE}
p <- ggplot(biohistbeta, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
p+facet_grid(.~variable, scales = "free_x")

q <- ggplot(biohistld50, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
q + 
  facet_grid(.~variable) +
  scale_x_continuous(limit = c(-0.75, 0.75))
```

Both approaches seem comparable, with the WINBUGS scheme centering more around the posterior mean values for each parameter compared the the MC method, but otherwise both methods produce similar results.

#####(c)	Repeat part (a) after multiplying each *n* above by *5* (i.e. $n = 25$).
```{r Q2c, include=FALSE}
#prepare the data for input into OpenBUGS
ni <- c(25,25,25,25)
data <- list ("xi", "yi", "ni","n")

#initialization of variables
inits <- function(){
  list(beta0=0,beta1=1)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("beta0", "beta1","LD50")

#run the model
bioassay.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.chains = 4, 
                    n.iter = 2500, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,
                    codaPkg = FALSE)

#R will pause. When model is complete a prompt will reappear
attach(bioassay.sim,warn.conflicts = FALSE)
```
```{r Q1bSummary}
bioassay.sim$summary
```
```{r Q2cData, include=FALSE}
bugsb0 <- as.data.frame(cbind(sims.list$beta0,scheme="BUGS2",variable="beta0"))
bugsb1 <- as.data.frame(cbind(sims.list$beta1,scheme="BUGS2",variable="beta1"))
bugsld50 <- as.data.frame(cbind(sims.list$LD50,scheme="BUGS2",variable="ld50"))

biohistbeta2 <- as.data.frame(rbind(biohistbeta,bugsb0, bugsb1))

biohistbeta <- as.data.frame(rbind(numb0,numb1,bugsb0,bugsb1))
biohistbeta$V1 <- as.numeric(as.character(biohistbeta$V1))

biohistld502 <- as.data.frame(rbind(biohistld50,bugsld50))
biohistld50 <- as.data.frame(rbind(numld50,bugsld50))
biohistld50$V1 <- as.numeric(as.character(biohistld50$V1))
```
```{r Q2cHists, echo = FALSE, warning = FALSE}
p <- ggplot(biohistbeta, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
p + facet_grid(.~variable, scales = "free_x")
q <- ggplot(biohistld50, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
q + 
  facet_grid(.~variable, scales = "free") +
  scale_x_continuous(limit = c(-1, 5))
```

The multiplication in this example has change the underlying problem, and we can see the change when comparing the histograms for the MC (num) method and the BUGS method. By multiplying each n by 5 we have altered proportion of rats that die for each log-dosage, thereby reducing our estimates of toxicity.

#####(d) Repeat part (a) after multiplying each *n* **AND** each *y* above by *5*.
```{r Q2dBUGS, , include = FALSE}
#prepare the data for input into OpenBUGS
ni <- c(25,25,25,25)
yi <- c(0,5,15,25)
data <- list ("xi", "yi", "ni","n")

#initialization of variables
inits <- function(){
  list(beta0=0,beta1=1)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("beta0", "beta1","LD50")

#run the model
bioassay.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.chains = 4, 
                    n.iter = 2500, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,
                    codaPkg = FALSE)

#R will pause. When model is complete a prompt will reappear
attach(bioassay.sim,warn.conflicts = FALSE)
```
```{r Q2dData, include = FALSE}
bugsb0 <- as.data.frame(cbind(sims.list$beta0,scheme="BUGS3",variable="beta0"))
bugsb1 <- as.data.frame(cbind(sims.list$beta1,scheme="BUGS3",variable="beta1"))
bugsld50 <- as.data.frame(cbind(sims.list$LD50,scheme="BUGS3",variable="ld50"))

biohistbeta2 <- as.data.frame(rbind(biohistbeta2,bugsb0, bugsb1))

biohistbeta <- as.data.frame(rbind(numb0,numb1,bugsb0,bugsb1))
biohistbeta$V1 <- as.numeric(as.character(biohistbeta$V1))

biohistld502 <- as.data.frame(rbind(biohistld502,bugsld50))

biohistld50 <- as.data.frame(rbind(numld50,bugsld50))
biohistld50$V1 <- as.numeric(as.character(biohistld50$V1))
```
```{r Q2dHists, echo=FALSE, warning = FALSE}
bioassay.sim$summary
p <- ggplot(biohistbeta, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
p+facet_grid(~variable, scales = "free_x")

q <- ggplot(biohistld50, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
q + 
  facet_grid(.~variable) +
  scale_x_continuous(limit = c(-0.75, 0.75))
```
We again have a much better estimate compared to part (c) because. by multiplying both the n and y value for each dosage level, we have not fundamentally changed the underlying toxicity estimate from the problem as it was originally stated.

#####(e)	Compare inferences for $\alpha$, $\beta$ and *LD50*: how have they changed from **(a)** to **(c)** and **(d)**? Do these	changes make logical sense?
```{r Q2eHists, echo=FALSE, warning = FALSE}
biohistbeta2$V1 <- as.numeric(as.character(biohistbeta2$V1))
biohistld502$V1 <- as.numeric(as.character(biohistld502$V1))

p <- ggplot(biohistbeta2, aes(x = V1, fill = scheme)) + stat_bin(bins = 100) 
p + facet_grid(.~variable, scales = "free")

q <- ggplot(biohistld502, aes(x = V1, group = scheme, fill = scheme)) + stat_bin(bins = 500) 

q + 
  facet_grid(.~variable) +
  scale_x_continuous(limit = c(-0.5, 3))

```



Yes, for the reasons stated above. The estimate from part (c) should look much different from the others because the data used to estimate it is skewed compared to the others: more trials for the same number of deaths. Additionally, we can see that the best estimate is the one obtained in part (d), which makes sense because it has the largest sample and therefore the least variability.


##Question 2

```{r Q2data, include=FALSE}
data("birthweight")
attach(birthweight)
birthweight$gender <- as.factor(birthweight$gender)
levels(birthweight$gender) <- c("Male","Female")
```

**Taken from Albert (2007). Normal linear regression.**

Dobson (2001) describes a birthweight regression study. One is interested in predicting a baby’s birthweight (in grams) based on the gestational age (in weeks) and the gender of the baby. The data is presented in the file *birthweight.txt*. In the standard linear regression model, we assume that
$$
\text{Birthweight (i)} = \beta_{0} + \beta_{1}\,AGE\,(i) + \beta_{2}\,GENDER\,(i) + e(i)
$$
where the *e(i)’s* are independent and Normally distributed random variables with mean **0** and variance $\sigma^{2}$.

#####(a) Use the R function lm to fit this model by Least-Squares. From the output, assess if the effects AGE and GENDER are significant, and if they are significant, describe the effects of each covariate on birthweight.

```{r Q2a}
fit <- lm(weight ~ age + gender, data = birthweight, model = TRUE, x=TRUE,y=TRUE)
summary(fit)
```
From the output of the linear model we can see that age is the only covariate that significantly effects birthweight ($\alpha = 0.05$). It has a positive effect on birthweight - i.e. as age increases, so does birthweight. Gender - which is not found to have a significant impact on birthweight - negatively effects birthweight if the child is female; it effects bw positively if the child is male. The value of the intercept is given as $\approx -924.94$.

#####(b)	Suppose a uniform prior is placed on the regression parameters $\beta$ = ($\beta_{0}$, $\beta_{1}$, $\beta_{2}$). Use the LearnBayes package in R (blinreg command) to simulate an MC sample of **5000** draws from the joint posterior distribution of ($\beta$, $\sigma^{2}$). From the simulated sample, compute posterior means and standard deviations of $\beta_{1}$ and $\beta_{2}$. Compare the results with the LS estimates obtained in **(a)**.

```{r Q2b_blinreg}
theta.sample <- blinreg(fit$y,fit$x,5000)
sumresids <- sum(fit$residual^2)
shape <- fit$df.residual/2
rate <- sumresids/2
sigma2 <- rigamma(1,shape,rate)
MSE <-  sum(fit$residuals^2)/fit$df.residual
vbeta <- vcov(fit)/MSE
beta <- rmnorm(1,mean=fit$coef,varcov=vbeta*sigma2)
```

```{r Q2b_plot}
par(mfrow=c(1,2))
hist(theta.sample$beta[,2],main="Age",xlab=expression(beta[1]), 30)
hist(theta.sample$beta[,3],main="Gender", xlab=expression(beta[2]),30)
hist(theta.sample$sigma,main="Error StdDev", xlab=expression(sigma))
# CIs for the Beta coefficients
apply(theta.sample$beta,2,quantile,c(.05,.5,.95))
# CIs for sigma
quantile(theta.sample$sigma,c(.05,.5,.95))
```
Here we are given values for the Intercept, Age coefficient and Gender coefficient of approximately $-907.2544, 102.49836$ and $-119.5783$ respectively, which are pretty close to the values obtained using the method in part (a).

#####(c) Repeat part **(b)** using WinBUGS. Compare the results with the LS estimates obtained in **(a)** and MC sampling in part **(b)**.

```{r Q1BUGS, cache=TRUE}
require(R2OpenBUGS)
require(coda)

#define the model
birthweightmodel <- function(){
  for (i in 1:n) {
    mu[i] <- beta0 + beta1*x1[i] + beta2*x2[i]
    yi[i] ~ dnorm(mu[i],tau) 
  } 
  beta0 ~  dflat()
  sigma ~ dunif(0.01, 100)
  tau <- 1/(sigma*sigma)
  beta1 ~  dflat()
  beta2 ~  dflat()
}
# write the model code out to a file
write.model(birthweightmodel, "birthweightmodel.txt")
model.file1 = paste(getwd(),"birthweightmodel.txt", sep="/")

#prepare the data for input into OpenBUGS
x1 <- fit$model[,2]
x2 <- as.integer(unclass(fit$model[,3]))
yi <- fit$model[,1]
n <- 24
data <- list("x1","x2","yi","n")

#initialization of variables
inits <- function(){
  list(beta0=0, beta1=1,beta2=1,sigma=1)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("beta0", "beta1","beta2")

#run the model
birthweight.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.chains = 5, 
                    n.iter = 10000, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,
                    codaPkg = T,
                    working.directory = getwd(),
                    debug = F)

samples <- read.openbugs()
plot(samples)
summary(samples)
```

WINBUGS reports values for the Intercept, Age coefficient and Gender coefficient of approximately $-718.8, 100.9$ and $-123.1$ respectively. The value given to the intercept is much lower than the values reported in parts (a) and (b), however the other coefficients are roughly the same as those calculated using the other methods.

##Question 3
**Variance components model, taken from Box & Tiao (1973).**
```{r Q3data, include=FALSE}
dyedata <- readRDS("Data/dyestuff.rds")
dyedata <- t(dyedata)
```
Read the complete WinBUGS example “Dyes: variance components model” (Examples Vol. 1). To show the advantages of the Bayesian approach, Box & Tiao also simulated data from a model with a known between batch variance of 4 and a within batch variance of *16*, presented in *dyestuff.txt*.

#####(a) Use WinBUGS to plot estimated posterior densities of the two variance components, including the joint posterior (by scatterplot), and give appropriate 95% intervals.

```{r Q3BUGS, cache=FALSE}
require(R2OpenBUGS)
require(coda)

#define the model
dyesmodel <- function(){
  for(i in 1 : batches) {
    m[i] ~ dnorm(theta, tau.btw)
    for(j in 1 : samples) {
      y[j , i] ~ dnorm(m[i], tau.with)
    }
  }
  sigma2.with <- 1 / tau.with
  sigma2.btw <- 1 / tau.btw
  tau.with ~ dgamma(0.001, 0.001)
  tau.btw ~ dgamma(0.001, 0.001)
  theta ~ dflat()
}
# write the model code out to a file
write.model(dyesmodel, "dyesmodel.txt")
model.file1 = paste(getwd(),"dyesmodel.txt", sep="/")
coda.file = paste(getwd(),"Q3Coda", sep="/")
## and let's take a look:
# file.show("dyesmodel.txt")

#prepare the data for input into OpenBUGS
batches <- 6
samples <- 5
y <- as.matrix(dyedata)  
data <- list ("batches","samples","y")

#initialization of variables
inits <- function(){
  list(theta=0, tau.with=1, tau.btw=1)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("sigma2.with","sigma2.btw","theta")

#run the model
dyes.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.burnin = 25000,
                    n.chains = 3, 
                    n.iter = 125000, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,
                    codaPkg = T,
                    working.directory = coda.file,
                    debug = F)
```

```{r Q3samp}
samples <- read.openbugs(paste0(coda.file,"/"))
samples2 <- as.matrix(samples[1])
```

```{r Q3plot}
plot(samples)
summary(samples)
plot(samples2[,"sigma2.with"],samples2[,"sigma2.btw"])
```

##Question 4
```{r Q4Data, include = FALSE}
strdata <- c(46,58,40,47,47,53,43,48,50,55,49,50,52,56,49,54,51,50,52,50)
```
The observed breaking strengths (in grams) of 20 pieces of yarn randomly sampled from spinning machines in a certain production area are as follows:
$$
46\quad58\quad40\quad47\quad47\quad53\quad43\quad48\quad50\quad55\quad49\quad50\quad52\quad56\quad49\quad54\quad51\quad50\quad52\quad50
$$

Assume that breaking strengths are known to follow a Normal distribution, and that the mean breaking strength of yarn produced by machines in this area is known to be 51 grams. We are trying to estimate the variance, which we will now call $\theta$.

##### (a) What is the conjugate family of prior distributions for a Normal variance (not precision) when the mean is known?

For a Gaussian distribution with a known mean but unknown variance we use an Inverse Gamma. So, in full we combine $IG(\alpha,\beta)$
$$
p(\theta) \propto (\theta)^{-(\alpha + 1)} e^{-\beta/\theta},
$$
with the likelihood of the Gaussian $\sim N(\bar{y} = 51, \theta)$
$$
p(y \mid \theta) \propto (\theta)^{-n/2}e^{\sum_{i=1}^n(y_i-\bar{y})^2/2\theta} 
$$
to get a posterior Inverse Gamma $\sim IG(n+2\alpha/2,\beta +\sum_{i=1}^n(y_i-\bar{y})^2/2)$
$$
p(\bar{y},\theta \mid y) \propto (\theta)^{-\left(\frac{n+2\alpha}{2} + 1\right)} e^{-\left(\frac{\beta}{\theta} + \frac{\sum_{i=1}^n(y_i-\bar{y})^2}{2\theta}\right)}
$$

##### (b)	Suppose previous experience suggests that the expected value of $\theta$ is *12* and the variance of $\theta$ is *4*. What parameter values are needed for the prior distribution to match these moments?

Because $\theta$ follows an Inverse Gamma such that $p(\theta) \sim IG(\alpha,\beta)$, we have
$$
E[\theta] = \frac{\beta}{\alpha-1}, \qquad \alpha > 1 \\
E[\theta^2] = \frac{\beta^2}{(\alpha-1)^2(\alpha-2)}, \qquad \alpha > 2
$$
Assuming the derived values $E[\theta] = 12$ and $E[\theta^2] = 4$, we solve simultaneously to get
$$
\begin{aligned}
12 &= \frac{\beta}{\alpha-1} \\
\implies \quad  \beta&=  12(\alpha-1)\\
\implies \quad 4 &= \frac{12^2(\alpha-1)^2}{(\alpha-1)^2(\alpha-2)} \\
144  &= 4(\alpha - 2) \\
36 &= \alpha - 2 \\
\implies \quad \alpha &= 38 \\
\implies \quad \beta &= 444
\end{aligned}
$$

##### (c) What is the posterior distribution $p(\theta \mid y)$ for this data under the prior from the previous step?

If we sub $\alpha = 38$ and $\beta = 444$ into the posterior derived in part (a), we get
$$
p(\theta \mid y) \propto (\theta)^{-\left(\frac{n+76}{2} + 1\right)} e^{-\left(\frac{444}{\theta} + \frac{\sum_{i=1}^n(y_i-\bar{y})^2}{2\theta}\right)}
$$
which is $\sim IG\left(\frac{n+76}{2},444 + \frac{\sum_{i=1}^n(y_i-\bar{y})^2}{2}\right)$

```{r Q4c}
invgamm<-function(x,a,b){ 
lg = a*log(b)-lgamma(a)-(a+1)*log(x)-b/x 
return(exp(lg))} 
n <- length(strdata)
A=(n + 76)/2
B= 444 + ((n-1)*var(strdata))/2
x=seq(0,30,by=0.01) 
plot(x,invgamm(x,A,B),type='l') 

```

##### (d) Find the posterior mean and variance of $\theta$.

```{r Q4d}
g <- rgamma(10000,A,B) 
CI <- quantile(1/g,c(0.05,0.95)) 
# Confidence Intervale for theta
CI
# Posterior Mean for theta
mean(1/g)
# Posterior Variance for theta
var(1/g)
```

##### (e)	Now use WinBUGS to carry out the analysis. You will have to specify the model in terms of the precision.

I've made a mistake somewhere here. I'm not sure where. The

```{r Q4BUGS, cache=FALSE}
require(R2OpenBUGS)
require(coda)

strdata <- c(46,58,40,47,47,53,43,48,50,55,49,50,52,56,49,54,51,50,52,50)
#define the model
strmodel <- function() {
  for (i in 1:n) {
    x[i] ~ dnorm(mu,tau)
  }
  
  sigma ~ dunif(0.1,100)
  tau <- 1/(sigma*sigma)
}

# write the model code out to a file
write.model(strmodel, "strmodel.txt")
model.file1 = paste(getwd(),"strmodel.txt", sep="/")
coda.file = paste(getwd(),"Q4Coda", sep="/")
file.show("strmodel.txt")

#prepare the data for input into OpenBUGS
x <- strdata
mu <- 51
n <- length(strdata)
data <- list("x","mu","n")

#initialization of variables
inits <- function(){
  list(sigma=2)
}

WINE="/opt/local/bin/wine"
WINEPATH="/opt/local/bin/winepath"
OpenBUGS.pgm="/Users/benjamin/Applications/wine/drive_c/ProgramFiles/OpenBUGS/OpenBUGS323/OpenBUGS.exe"

#these are the parameters to save
parameters = c("sigma")

#run the model
str.sim <- bugs(data, 
                    inits, 
                    model.file = model.file1,
                    parameters=parameters,
                    n.chains = 3, 
                    n.iter = 1000, 
                    OpenBUGS.pgm=OpenBUGS.pgm, 
                    WINE=WINE, 
                    WINEPATH=WINEPATH,
                    useWINE=T,                    
                    codaPkg = T,
                    working.directory = coda.file,
                    debug = F)

```

```{r Q4samp}
samples <- read.openbugs(paste0(coda.file,"/"))
```

```{r Q4plot}
plot(samples)
summary(samples)
```


###End of Assignment 3