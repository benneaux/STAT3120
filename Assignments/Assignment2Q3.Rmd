---
title: "Assignment2Q3"
author: "Benjamin G. Moran; <right> c3076448@uon.edu.au </right>"
date: "22nd August 2016"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document:
    graphics: yes
    highlight: pygments
    includes:
      before_body: eqnnumber.js
    mathjax: default
    smart: yes
subtitle: <center> Semester 2, 2016 </center>
---

```{r setup, include=FALSE}
require(tufte)
require(knitr)
require(dplyr)
require(reshape2)
require(tidyr)
opts_chunk$set(fig.align = 'center', fig.height = 6, fig.width = 12, collapse = TRUE, highlight = TRUE)
```
##Question 3	[Total: 20 marks]

Consider the example on corn yields but with an extended data set, with sample sizes, sample means and sample variances as given below. We have five different corn growers giving individual yields for a particular new type of genetically engineered corn that has three seasons per year. The corn is distributed by a research station to the growers. Growers give yields for the most recent seasons in tons/hectare. Summary statistics for the data are given below.

```{r Q3 table, echo=FALSE}
row.symbols = c(ni='n\U1D62', ybar='y\u0305\U1D62', sigmaSq="s\U00B2\U1D62")
q3.table = matrix(c(16, 15.3, 8.2, 19, 16.2, 12.3, 14, 16.4, 7.9, 12, 13.2, 5.2, 8, 13.5, 6.2), 3, 5)
colnames(q3.table) = c("1", "2", "3","4", "5")
row.labels = c(row.symbols['ni'], row.symbols['ybar'], row.symbols['sigmaSq'])
rownames(q3.table) = row.labels
kable(q3.table, align = rep(c("c","c"), dim(q3.table)[2] + 1), caption = "Corn Yield Data by Grower", escape = TRUE)
```

```{r Q3 Data, echo = FALSE}

n <- c(16, 19, 14, 12, 8)
y.bar <- c(15.3, 16.2, 16.4, 13.2, 13.5)
sig2 <- c(8.2, 12.3, 7.9, 5.2, 6.2)

```

(a)	By adapting code from the week 7 lecture, fit a hierarchical Normal model to this data, using the Empirical Bayes approach. Provide estimates and inference for each unknown true grower mean yield, including a plot showing all estimated posterior densities, one for each unknown mean.	[7 marks]

**Answer:** The lecture material presents us with 3 possible models, however only one is represented by the code in those same notes: the model that makes no assumptions about individual grower variances (3). So, the model we must fit to our data is a non-standard posterior distribution that is constructed by multiplying a Normal prior with the likelihood for $\mu_{j}$ in the form of a t-density.

$$
  \begin{aligned}
  p(\mu_{j} \mid y_{j}, \mu, \tau^{2}) 
  &\propto p(y_{j} \mid \mu_{j}, \mu,\tau^{2})p(\mu_{j} \mid \mu, \tau^{2}) \\
  &=p(\mu_{j} \mid \mu, \tau^{2})  \int p(\mu_{j} \mid y_{j}, \sigma_{j}^{2}, \mu, \tau^{2})(\sigma_{j}^{2} \mid \mu, \tau^{2}) \\
  &\propto p(N(\mu,\tau^{2}))p(t_{n_{j} - 1}(\bar{y}_{j}, s_{j}^{2})/n_{j}))
  \end{aligned}
$$

For the choice of hyperparameters $\mu$ and $\tau$, we again proceed in line with the notes and calculate the average yield across all growers, along with the standard deviation of that average yield. This gives us our empirical priors, which we can use to perform the estimation. Plot
```{r Q3amanymeans}
x <- seq(5, 25, by=0.001)
mu <- mean(y.bar) # 14.92
tau <- sqrt(var(y.bar)) # 1.49566...
par(mfrow = c(1,2))
pdf.data <- matrix(nrow=5,ncol=20001)
for(k in 1:5){
  px <- -(x-mu)^2/(2*tau^2)-3/2*log(1+(3*(x-y.bar[k])^2)/(2*sig2[k]))
  pdf.data[k,] <- px
  if(k==1){
    plot(x,exp(px),type='l',col=k)
  } else {
    lines(x,exp(px),type='l', col = k)
  }
}
cdf.data <- matrix(nrow=5,ncol=20001)
for(k in 1:5) {
  px <- -(x-mu)^2/(2*tau^2) -3/2*log(1+(3*(x-y.bar[k])^2)/(2*sig2[k]))
  cdf.data[k,] <- exp(px)/sum(exp(px))
}

for(k in 1:5) {
  px <- cumsum(cdf.data[k,])
  if(k==1) {
    plot(x,px,type='l', col=k)
  } else {
    lines(x,px,type='l', col = k)
  }
}
```


We can generate MCMC samples using the following code (Note: I have not included the code for each grower to save space):

```{r MCMCex, eval=FALSE}
cdf1 <- cumsum(cdf.data[1,])
u=runif(1000,0,1)
mu1=0

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf1[k]<u[j]&cdf1[k+1]>u[j]) {
    mu1[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
    }
  }
}
```

```{r MCMC, cache = TRUE, echo = FALSE}
cdf1 <- cumsum(cdf.data[1,])
cdf2 <- cumsum(cdf.data[2,])
cdf3 <- cumsum(cdf.data[3,])
cdf4 <- cumsum(cdf.data[4,])
cdf5 <- cumsum(cdf.data[5,])

u=runif(1000,0,1)
mu1=0;mu2=0;mu3=0;mu4=0;mu5=0

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf1[k]<u[j]&cdf1[k+1]>u[j]) {
    mu1[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
    }
  }
}

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf2[k]<u[j]&cdf2[k+1]>u[j]) {
    mu2[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
  }
 }
}

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf3[k]<u[j]&cdf3[k+1]>u[j]) {
    mu3[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
  }
 }
}

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf4[k]<u[j]&cdf4[k+1]>u[j]) {
    mu4[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
  }
 }
}

for(j in 1:1000){
 st=0;k=1
 while(st==0) {
  if(cdf5[k]<u[j]&cdf5[k+1]>u[j]) {
    mu5[j] <- x[k]
    st <- 1
  } else {
    k <- k+1
  }
 }
}
```

Now, using our MCMC samples, we can calculate the posterior mean and CrI for each grower:

```{r means, echo = FALSE}
grower <- c(1,2,3,4,5)
means <- c(mean(mu1),mean(mu2),mean(mu3),mean(mu4),mean(mu5))
cil <- c(
  quantile(mu1,0.025),
  quantile(mu2,0.025),
  quantile(mu3,0.025),
  quantile(mu4,0.025),
  quantile(mu5,0.025)
  )
  
ciu <- c(
  quantile(mu1,0.975),
  quantile(mu2,0.975),
  quantile(mu3,0.975),
  quantile(mu4,0.975),
  quantile(mu5,0.975)
  )
int.data <- cbind(grower, means,cil,ciu)
kable(int.data, row.names = FALSE, col.names = c("Grower","Mean","2.5%","97.5%"))
```

This suggests an order (from the grower with the largest mean output to the lowest) of  $3,2,1,5,4$. Plotting the MCMC sample densities reaffirms this idea:

```{r MCMCplot, echo = FALSE}
plot(density(mu1),type='l',col=1, main="MCMC Densities")
text(mean(mu1),0.025, "mu1", col = 1, adj = c(-0.1, -0.1))
abline(v=mean(mu1), lty=3, col = 1)
lines(density(mu2),col=2)
text(mean(mu2),0.05, "mu3", col = 2, adj = c(-0.1, -0.1))
abline(v=mean(mu2), lty=3, col = 2)
lines(density(mu3),col=3)
text(mean(mu3),0, "mu3", col = 3, adj = c(-0.1, -0.1))
abline(v=mean(mu3), lty=3, col = 3)
lines(density(mu4),col=4)
text(mean(mu4),0, "mu4", col = 4, adj = c(-0.1, -0.1))
abline(v=mean(mu4), lty=3, col = 4)
lines(density(mu5),col=5)
text(mean(mu5),0.05, "mu5", col = 5, adj = c(-0.1, -0.1))
abline(v=mean(mu5), lty=3, col = 5)


```

(b) Plot the estimated parent density for the five grower means. At what percentile of this distribution does of each growerâ€™s estimated posterior mean yield lie? Do they all fit in with the prior distribution? [2 marks]
```{r Parentdata}
x.parent <- seq(5,25,by=0.001)
parent.data <- dnorm(x.parent,mu,tau)
plot(x.parent,parent.data, type = 'l')
```

We can easily calculate the corresponding percentile of the parent distribution for each posterior mean by:

```{r parentmeans}
# Grower 1
mu1.p <- round(mean(x.parent<mean(mu1))*100,2)
# Grower 2
mu2.p <- round(mean(x.parent<mean(mu2))*100,2)
# Grower 3
mu3.p <- round(mean(x.parent<mean(mu3))*100,2)
# Grower 4
mu4.p <- round(mean(x.parent<mean(mu4))*100,2)
# Grower 5
mu5.p <- round(mean(x.parent<mean(mu5))*100,2)
```

This tells us that the posterior means for Growers 1 through 5 are: 

```{r pmeanstable, echo=FALSE}
row.n <- c("Percentile")
parent.perc <- cbind(row.n, mu1.p,mu2.p,mu3.p,mu4.p,mu5.p)
kable(parent.perc, col.names = c("Grower","1","2","3","4","5"))
```



(c) What is the posterior probability that each of the five growers has the largest mean yield? What is your conclusion in this case? [2 marks]

```{r MCMC2, echo = FALSE}

probs <- matrix(nrow = 5, ncol = 5)
n <- 1000
probs[1,1] <- length(mu1[mu1>mu1])/n # 0
probs[1,2] <- length(mu1[mu1>mu2])/n # 0
probs[1,3] <- length(mu1[mu1>mu3])/n # 0
probs[1,4] <- length(mu1[mu1>mu4])/n # 1
probs[1,5] <- length(mu1[mu1>mu5])/n # 1

probs[2,1] <- length(mu2[mu2>mu1])/n # 1
probs[2,2] <- length(mu2[mu2>mu2])/n # 0
probs[2,3] <- length(mu2[mu2>mu3])/n # 0.01
probs[2,4] <- length(mu2[mu2>mu4])/n # 1
probs[2,5] <- length(mu2[mu2>mu5])/n # 1

probs[3,1] <- length(mu3[mu3>mu1])/n # 1
probs[3,2] <- length(mu3[mu3>mu2])/n # 0.99
probs[3,3] <- length(mu3[mu3>mu3])/n # 0
probs[3,4] <- length(mu3[mu3>mu4])/n # 1
probs[3,5] <- length(mu3[mu3>mu5])/n # 1

probs[4,1] <- length(mu4[mu4>mu1])/n # 0
probs[4,2] <- length(mu4[mu4>mu2])/n # 0
probs[4,3] <- length(mu4[mu4>mu3])/n # 0
probs[4,4] <- length(mu4[mu4>mu4])/n # 0
probs[4,5] <- length(mu4[mu4>mu5])/n # 0

probs[5,1] <- length(mu5[mu5>mu1])/n # 0
probs[5,2] <- length(mu5[mu5>mu2])/n # 0
probs[5,3] <- length(mu5[mu5>mu3])/n # 0
probs[5,4] <- length(mu5[mu5>mu4])/n# 1
probs[5,5] <- length(mu5[mu5>mu5])/n # 0
```

We can calculate these probabilities fairly simply, using the MCMC estimates for the posterior means of each grower and the following code:

```{r Q3c}
# Grower 1
length(mu1[mu1>mu2&mu1>mu3&mu1>mu4&mu1>mu5])/n
# Grower 2
length(mu2[mu2>mu1&mu2>mu3&mu2>mu4&mu2>mu5])/n
# Grower 3
length(mu3[mu3>mu1&mu3>mu2&mu3>mu4&mu3>mu5])/n
# Grower 4
length(mu4[mu4>mu1&mu4>mu2&mu4>mu3&mu4>mu5])/n
# Grower 5
length(mu5[mu5>mu1&mu5>mu2&mu5>mu3&mu5>mu4])/n
```

This tells us that, using our estimates, Grower 3 has the largest mean yield with a probability of $\approx$ `r length(mu3[mu3>mu1&mu3>mu2&mu3>mu4&mu3>mu5])/n*100`%.



(d) What is the posterior probability that, for each pair of growers (grower i and i+k), the mean yield for grower(i) exceeds the mean yield for grower (i+k)? [2 marks]

```{r Q3b}
# Probability that mean of Grower A (Row) is greater than mean of Grower B (Column)
colnames(probs) <- c("1","2","3","4","5")
rownames(probs) <- c("1","2","3","4","5")
probs.m <- melt(probs)

probs.m <- as.data.frame(probs.m)
names(probs.m) <- c("GrowerA", "GrowerB", "Pr")
probs.m <- probs.m %>%
  arrange(GrowerA,desc(Pr))

kable(probs.m, row.names = FALSE, col.names = c("Grower A", "Grower B", "Pr(A>B)"))
length(mu3[mu3<mu2&mu3>mu1&mu3>mu5&mu3>mu4])/n
length(mu2[mu2<mu3&mu2<mu1&mu2>mu5&mu2>mu4])/n
length(mu1[mu1<mu3&mu1>mu2&mu1>mu5&mu1>mu4])/n
```

```{r Q2d}
length(mu3[mu3>mu2&mu3>mu1&mu3>mu5&mu3>mu4])/n
length(mu2[mu2<mu3&mu2>mu1&mu2>mu5&mu2>mu4])/n
length(mu1[mu1<mu3&mu1<mu2&mu1>mu5&mu1>mu4])/n
length(mu5[mu5<mu3&mu5<mu2&mu5<mu1&mu5>mu4])/n
length(mu4[mu4<mu3&mu4<mu2&mu4<mu1&mu4<mu5])/n
length(mu3[mu3<mu2&mu3>mu1&mu3>mu5&mu3>mu4])/n
length(mu2[mu2<mu3&mu2<mu1&mu2>mu5&mu2>mu4])/n
length(mu1[mu1<mu3&mu1>mu2&mu1>mu5&mu1>mu4])/n
```

(e) What is the most likely ordering for the 5 mean grower yields in your MC sample? What are the 2nd, 3rd and 4th most likely orderings? [4 marks]

```{r probss}
length(mu3[mu3>mu2&mu3>mu1&mu3>mu5&mu3>mu4])/n
length(mu2[mu2<mu3&mu2>mu1&mu2>mu5&mu2>mu4])/n
length(mu1[mu1<mu3&mu1<mu2&mu1>mu5&mu1>mu4])/n
length(mu5[mu5<mu3&mu5<mu2&mu5<mu1&mu5>mu4])/n
length(mu4[mu4<mu3&mu4<mu2&mu4<mu1&mu4<mu5])/n
```

(f)	Based on (a)-(d), and any other evidence you can provide, where do you believe significant differences exist among the 5 grower means (if any)? [3 marks]

###End of Assignment 2